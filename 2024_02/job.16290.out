Namespace(batch_size=32, conf_thres=0.03, config_file='', data='data/duo.yaml', device='0', do_coco_metric=True, do_pr_metric=False, eval_config_file='./configs/experiment/eval_640_repro.py', force_no_pad=True, half=False, img_size=640, iou_thres=0.65, letterbox_return_int=True, name='exp', not_infer_on_rect=True, plot_confusion_matrix=False, plot_curve=True, reproduce_640_eval=True, save_dir='runs/val/', scale_exact=True, task='val', test_load_size=638, verbose=True, weights='runs/train/GOLD_YOLO_RGB_Fusion24/weights/best_ckpt.pt')
Loading checkpoint from runs/train/GOLD_YOLO_RGB_Fusion24/weights/best_ckpt.pt

Fusing model...
/public/home/hpc36037/.conda/envs/ljj_cuda11/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Switch model to deploy modality.
Model Summary: Params: 23.93M, Gflops: 72.29
Val: Checking formats of labels with 8 process(es): 
./data/duo/test
  0%|          | 0/1111 [00:00<?, ?it/s]904 label(s) found, 0 label(s) missing, 6 label(s) empty, 0 invalid label files:  81%|████████▏ | 904/1111 [00:00<00:00, 8558.61it/s]1111 label(s) found, 0 label(s) missing, 11 label(s) empty, 0 invalid label files: 100%|██████████| 1111/1111 [00:00<00:00, 10034.87it/s]
Val: Final numbers of valid images: 1111/ labels: 1111. 
0.8s for dataset initialization.
Inferencing model in val datasets.:   0%|                | 0/35 [00:00<?, ?it/s]Inferencing model in val datasets.:   3%|▏       | 1/35 [00:03<01:42,  3.02s/it]Inferencing model in val datasets.:   6%|▍       | 2/35 [00:03<00:48,  1.48s/it]Inferencing model in val datasets.:   9%|▋       | 3/35 [00:03<00:33,  1.04s/it]Inferencing model in val datasets.:  11%|▉       | 4/35 [00:04<00:25,  1.20it/s]Inferencing model in val datasets.:  14%|█▏      | 5/35 [00:04<00:20,  1.48it/s]Inferencing model in val datasets.:  17%|█▎      | 6/35 [00:05<00:16,  1.72it/s]Inferencing model in val datasets.:  20%|█▌      | 7/35 [00:05<00:14,  1.91it/s]Inferencing model in val datasets.:  23%|█▊      | 8/35 [00:06<00:12,  2.09it/s]Inferencing model in val datasets.:  26%|██      | 9/35 [00:06<00:11,  2.20it/s]Inferencing model in val datasets.:  29%|██     | 10/35 [00:06<00:10,  2.35it/s]Inferencing model in val datasets.:  31%|██▏    | 11/35 [00:07<00:10,  2.34it/s]Inferencing model in val datasets.:  34%|██▍    | 12/35 [00:07<00:09,  2.33it/s]Inferencing model in val datasets.:  37%|██▌    | 13/35 [00:08<00:09,  2.28it/s]Inferencing model in val datasets.:  40%|██▊    | 14/35 [00:08<00:08,  2.41it/s]Inferencing model in val datasets.:  43%|███    | 15/35 [00:08<00:08,  2.27it/s]Inferencing model in val datasets.:  46%|███▏   | 16/35 [00:09<00:07,  2.40it/s]Inferencing model in val datasets.:  49%|███▍   | 17/35 [00:09<00:07,  2.34it/s]Inferencing model in val datasets.:  51%|███▌   | 18/35 [00:10<00:07,  2.38it/s]Inferencing model in val datasets.:  54%|███▊   | 19/35 [00:10<00:06,  2.42it/s]Inferencing model in val datasets.:  57%|████   | 20/35 [00:11<00:06,  2.44it/s]Inferencing model in val datasets.:  60%|████▏  | 21/35 [00:11<00:05,  2.44it/s]Inferencing model in val datasets.:  63%|████▍  | 22/35 [00:11<00:05,  2.45it/s]Inferencing model in val datasets.:  66%|████▌  | 23/35 [00:12<00:04,  2.48it/s]Inferencing model in val datasets.:  69%|████▊  | 24/35 [00:12<00:04,  2.41it/s]Inferencing model in val datasets.:  71%|█████  | 25/35 [00:13<00:04,  2.42it/s]Inferencing model in val datasets.:  74%|█████▏ | 26/35 [00:13<00:03,  2.48it/s]Inferencing model in val datasets.:  77%|█████▍ | 27/35 [00:13<00:03,  2.30it/s]Inferencing model in val datasets.:  80%|█████▌ | 28/35 [00:14<00:02,  2.33it/s]Inferencing model in val datasets.:  83%|█████▊ | 29/35 [00:14<00:02,  2.38it/s]Inferencing model in val datasets.:  86%|██████ | 30/35 [00:15<00:02,  2.41it/s]Inferencing model in val datasets.:  89%|██████▏| 31/35 [00:15<00:01,  2.38it/s]Inferencing model in val datasets.:  91%|██████▍| 32/35 [00:15<00:01,  2.49it/s]Inferencing model in val datasets.:  94%|██████▌| 33/35 [00:16<00:00,  2.56it/s]Inferencing model in val datasets.:  97%|██████▊| 34/35 [00:16<00:00,  2.57it/s]Inferencing model in val datasets.: 100%|███████| 35/35 [00:17<00:00,  2.74it/s]Inferencing model in val datasets.: 100%|███████| 35/35 [00:17<00:00,  2.06it/s]

Evaluating speed.
Average pre-process time: 0.35 ms
Average inference time: 5.27 ms
Average NMS time: 0.80 ms

Evaluating mAP by pycocotools.
Saving runs/val/exp1/predictions.json...
Class           Labeled_images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95
all                     1100       10517       0.826        0.76       0.792       0.848       0.662
holothurian              490        1079       0.911         0.8       0.852       0.884       0.663
echinus                  967        7201        0.89        0.86       0.875       0.908        0.73
scallop                   78         217       0.865        0.56        0.68        0.68       0.513
starfish                 659        2020       0.905        0.87       0.887       0.921       0.742
Results saved to runs/val/exp1
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Loading and preparing results...
DONE (t=0.80s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=14.47s).
Accumulating evaluation results...
DONE (t=1.26s).
----model.nc----
4
[{'images': set(), 'anns': 0}, {'images': set(), 'anns': 0}, {'images': set(), 'anns': 0}, {'images': set(), 'anns': 0}]
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.848
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.738
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.763
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.779
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.746
